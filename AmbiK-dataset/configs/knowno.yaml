experiment: 
  examples_generation:
    model: "TheBloke/Mistral-7B-Instruct-v0.1-AWQ"
    generation_kwargs:
      max_new_tokens: 256
      do_sample: false
      #temperature: 0.7
      #top_p: 0.9
      #num_return_sequences: 1

  answering:
    model: "google/flan-t5-large"
    generation_kwargs:
      max_new_tokens: 1
      do_sample: false
