# MIPT_RoboUncertainty_AmbiK_project

### **Проблема и пути решения**

Работа посвящена задаче обнаружения неоднозначностей в инструкциях на естественном языке для кухонного робота, представленных в датасете **AmbiK**. Такие неоднозначности могут быть вызваны неполнотой информации, предпочтениями пользователя или отсутствием знаний у модели. Цель — улучшить поведение LLM в условиях неопределенности: чтобы она либо уверенно выбирала действие, либо запрашивала помощь, если не уверена.

Для этого был адаптирован метод **оценки неопределенности через энтропию** логитов, получаемых из модели. Если энтропия превышает заданный порог, модель "просит помощь", что интерпретируется как необходимость уточнения задания у пользователя.

### **Выбранный подход LM-Polygraph**

Был выбран метод на основе **энтропии выходных логитов модели** из статьи *LM-Polygraph: Uncertainty Estimation for Language Models*.

- Для генерации вариантов действий использовалась модель **Mistral-7B-Instruct (AWQ)**.
- Для выбора действия из предложенных опций — **Flan-T5-Large**.
- Порог для энтропии определялся эмпирически и использовался для определения, нужно ли запрашивать помощь.
- При превышении порога модель не делает однозначного выбора, а "просит помощь", что отражается в метриках (`help_rate`, `correct_help_rate`).

### **Плюсы и минусы подхода**

**Плюсы:**
- Простота интеграции в уже существующий пайплайн (KnowNo).
- Метод не требует обучения или дополнительной модели.
- Хорошо переносится на другие LLM и задачи.

**Минусы:**
- Порог энтропии нужно калибровать вручную или дополнительно автоматизировать.
- В отдельных случаях модель может избыточно запрашивать помощь.
- Не учитываются семантические особенности самого задания — используется только уровень неопределенности по выходу.


### **Анализ полученных результатов**

Полученные результаты метрик залогированы здесь: https://wandb.ai/mlunov-hse-university/ambik-knowno?nw=nwusermlunov

#### **Сравнение метрик с бейзлайном:**

| **Ambiguity Type**           | **Метрика**            | **KnowNo (базовый)** | **KnowNo с энтропией** |
|-----------------------------|-------------------------|----------------------|------------------------|
| **Unambiguous**             | Success Rate (SR)       | 0.540                | 0.520                  |
|                             | Correct Help Rate       | 0.980                | 0.720                  |
|                             | Help Rate               | 0.020                | 0.280                  |
|                             | SSC                     | -                    | -                      |
| **Preferences**             | Success Rate (SR)       | 0.250                | 0.250                  |
|                             | Correct Help Rate       | 0.042                | 0.333                  |
|                             | Help Rate               | 0.042                | 0.333                  |
|                             | SSC                     | 0.108                | 0.108                  |
| **Common Sense Knowledge**  | Success Rate (SR)       | 0.447                | 0.447                  |
|                             | Correct Help Rate       | 0.105                | 0.316                  |
|                             | Help Rate               | 0.105                | 0.316                  |
|                             | SSC                     | 0.000                | 0.000                  |
| **Safety**                  | Success Rate (SR)       | 0.571                | 0.286                  |
|                             | Correct Help Rate       | 0.000                | 0.286                  |
|                             | Help Rate               | 0.000                | 0.286                  |
|                             | SSC                     | -                    | -                      |

### **Интерпретация результатов**

- **SR (Success Rate)** остался примерно таким же в категориях `preferences` и `common_sense_knowledge`, снизился в `safety`, и немного упал в `unambiguous_direct`. Это говорит о том, что модель чаще **перестраховывалась** в ясных ситуациях.
- **Help Rate** и **Correct Help Rate** существенно **выросли** во всех типах неоднозначностей (в частности, `preferences`, `common_sense_knowledge` и `safety`). Это означает, что модель **успешно научилась определять неопределенность** и просить помощь чаще — и, что важно, **в нужных случаях**.
- **SSC (Set Size Correctness)** осталась на прежнем уровне — в основном 0 или не применяется, что ожидаемо, так как этот показатель зависит от качества shortlist-ответов.

### **Вывод**

Модификация KnowNo с использованием **энтропийного порога** значительно **повысила чувствительность модели к неоднозначности**, особенно в сложных категориях (`preferences`, `safety`). Хотя это немного повлияло на SR в безопасных задачах, **повышение уровня осознанности модели о своей неуверенности** — важный шаг в сторону более надёжного поведения в реальных условиях.

В будущем можно попытаться реализовать другие подходы из статьи по списку, как для "White-box"подходов: **Mean Pointwise Mutual Information (MPMI)**, **Conditional PMI**, так и для "Black-box" методов: **Number of semantic sets (NumSets) (Lin et al., 2023)**, **Eccentricity (Ecc) (Lin et al., 2023)** или попытаться обучить отдельный **классификатор неоднозначности**.
